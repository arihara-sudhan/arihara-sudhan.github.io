SOURCE: "ChatGPT powered Learning"
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -[13/05/2025]
1. Tokenizing Text into Words and Sentences
"""
    Tokenizer Models: punkt (for words) & punkt_tab (for sentence)
    Methods: word_tokenize, sent_tokenize
"""

import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
nltk.download("punkt")
nltk.download("punkt_tab")
corpus = "I am Ari. I live in Tenkasi."
print(word_tokenize(corpus))
print(sent_tokenize(corpus))

"""
OUTPUTS
    ['I', 'am', 'Ari', '.', 'I', 'live', 'in', 'Tenkasi', '.']
    ['I am Ari.', 'I live in Tenkasi.']
"""
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -[15/05/2025]
2. Stopwords Removal
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

nltk.download("stopwords")
corpus = "I am Ari and I am a good guy, and he is not a good boy known by his good attitude."
stop_words = set(stopwords.words("english"))
filtered_words = [word for word in word_tokenize(corpus) if word.lower() not in stop_words]
print(filtered_words)
"""
    ['Ari', 'good', 'guy', ',', 'good', 'boy', 'known', 'good', 'attitude', '.']
"""
